{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Accounting and Market DD/PD Datasets\n",
    "\n",
    "This notebook merges the accounting-based and market-based distance-to-default (DD) and probability-of-default (PD) datasets into a single combined dataset.\n",
    "\n",
    "**Workflow:**\n",
    "1. Load the latest accounting and market datasets from `data/outputs/datasheet/`\n",
    "2. Merge on `['instrument', 'year']`\n",
    "3. Apply clear labeling to distinguish accounting vs market variables\n",
    "4. Save timestamped merged dataset with archiving (max 5 archives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository root: /Users/guillaumebld/Documents/Graduate_Research/Professor Abol Jalilvand/fall2025/risk_bank/risk_bank\n",
      "Output directory: /Users/guillaumebld/Documents/Graduate_Research/Professor Abol Jalilvand/fall2025/risk_bank/risk_bank/data/outputs/datasheet\n",
      "Archive directory: /Users/guillaumebld/Documents/Graduate_Research/Professor Abol Jalilvand/fall2025/risk_bank/risk_bank/archive/datasets\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Find repository root\n",
    "def find_repo_root(start: Path, marker: str = '.git') -> Path:\n",
    "    current = start.resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        if (candidate / marker).exists():\n",
    "            return candidate\n",
    "    return current\n",
    "\n",
    "base_dir = find_repo_root(Path.cwd())\n",
    "output_dir = base_dir / 'data' / 'outputs' / 'datasheet'\n",
    "archive_dir = base_dir / 'archive' / 'datasets'\n",
    "\n",
    "print(f\"Repository root: {base_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Archive directory: {archive_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_timestamp_cdt():\n",
    "    \"\"\"Generate timestamp in YYYYMMDD_HHMMSS format (CDT timezone)\"\"\"\n",
    "    cdt = pytz.timezone('America/Chicago')\n",
    "    return datetime.now(cdt).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "def archive_old_files(output_dir, archive_dir, dataset_type, max_keep=5):\n",
    "    \"\"\"Move old files of dataset_type to archive, keeping only max_keep most recent\"\"\"\n",
    "    pattern = str(output_dir / f\"{dataset_type}_*.csv\")\n",
    "    old_files = sorted(glob.glob(pattern), key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "    \n",
    "    # Move all existing files to archive\n",
    "    for old_file in old_files:\n",
    "        archive_path = archive_dir / os.path.basename(old_file)\n",
    "        shutil.move(old_file, str(archive_path))\n",
    "        print(f\"[ARCHIVE] Moved to archive: {os.path.basename(old_file)}\")\n",
    "    \n",
    "    # Clean up archive to keep only max_keep files\n",
    "    archive_pattern = str(archive_dir / f\"{dataset_type}_*.csv\")\n",
    "    archive_files = sorted(glob.glob(archive_pattern), key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "    \n",
    "    for old_archive in archive_files[max_keep:]:\n",
    "        os.remove(old_archive)\n",
    "        print(f\"[CLEANUP] Removed old archive: {os.path.basename(old_archive)}\")\n",
    "\n",
    "def get_latest_file(output_dir, dataset_type):\n",
    "    \"\"\"Get the most recent file of given dataset_type\"\"\"\n",
    "    pattern = str(output_dir / f\"{dataset_type}_*.csv\")\n",
    "    files = sorted(glob.glob(pattern), key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No {dataset_type} files found in {output_dir}\")\n",
    "    return files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading accounting data from: accounting_20251004_041436.csv\n",
      "Loading market data from: market_20251004_050613.csv\n",
      "\n",
      "Accounting dataset: 1425 rows\n",
      "Market dataset: 1404 rows\n"
     ]
    }
   ],
   "source": [
    "# Load latest accounting and market datasets\n",
    "accounting_file = get_latest_file(output_dir, 'accounting')\n",
    "market_file = get_latest_file(output_dir, 'market')\n",
    "\n",
    "print(f\"Loading accounting data from: {os.path.basename(accounting_file)}\")\n",
    "print(f\"Loading market data from: {os.path.basename(market_file)}\")\n",
    "\n",
    "df_accounting = pd.read_csv(accounting_file)\n",
    "df_market = pd.read_csv(market_file)\n",
    "\n",
    "print(f\"\\nAccounting dataset: {len(df_accounting)} rows\")\n",
    "print(f\"Market dataset: {len(df_market)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset: 1425 rows\n",
      "\n",
      "Column count:\n",
      "  Accounting: 16\n",
      "  Market: 59\n",
      "  Merged: 73\n",
      "\n",
      "Sample merged data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>year</th>\n",
       "      <th>DD_a</th>\n",
       "      <th>PD_a</th>\n",
       "      <th>DD_m</th>\n",
       "      <th>PD_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2016</td>\n",
       "      <td>17.191718</td>\n",
       "      <td>1.531595e-66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2017</td>\n",
       "      <td>22.140950</td>\n",
       "      <td>6.375977e-109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2018</td>\n",
       "      <td>46.873017</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>28.963232</td>\n",
       "      <td>9.560799e-185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.049042</td>\n",
       "      <td>7.285482e-10</td>\n",
       "      <td>4.133342</td>\n",
       "      <td>1.787627e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2020</td>\n",
       "      <td>12.092687</td>\n",
       "      <td>5.772411e-34</td>\n",
       "      <td>6.880048</td>\n",
       "      <td>2.991617e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2021</td>\n",
       "      <td>16.945177</td>\n",
       "      <td>1.044526e-64</td>\n",
       "      <td>10.279523</td>\n",
       "      <td>4.357884e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2022</td>\n",
       "      <td>13.409921</td>\n",
       "      <td>2.644752e-41</td>\n",
       "      <td>7.278021</td>\n",
       "      <td>1.693760e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABCB</td>\n",
       "      <td>2023</td>\n",
       "      <td>17.757759</td>\n",
       "      <td>7.505416e-71</td>\n",
       "      <td>10.586485</td>\n",
       "      <td>1.721396e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACNB</td>\n",
       "      <td>2019</td>\n",
       "      <td>17.095048</td>\n",
       "      <td>8.078189e-66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACNB</td>\n",
       "      <td>2020</td>\n",
       "      <td>16.942326</td>\n",
       "      <td>1.096400e-64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instrument  year       DD_a           PD_a       DD_m           PD_m\n",
       "0       ABCB  2016  17.191718   1.531595e-66        NaN            NaN\n",
       "1       ABCB  2017  22.140950  6.375977e-109        NaN            NaN\n",
       "2       ABCB  2018  46.873017   0.000000e+00  28.963232  9.560799e-185\n",
       "3       ABCB  2019   6.049042   7.285482e-10   4.133342   1.787627e-05\n",
       "4       ABCB  2020  12.092687   5.772411e-34   6.880048   2.991617e-12\n",
       "5       ABCB  2021  16.945177   1.044526e-64  10.279523   4.357884e-25\n",
       "6       ABCB  2022  13.409921   2.644752e-41   7.278021   1.693760e-13\n",
       "7       ABCB  2023  17.757759   7.505416e-71  10.586485   1.721396e-26\n",
       "8       ACNB  2019  17.095048   8.078189e-66        NaN            NaN\n",
       "9       ACNB  2020  16.942326   1.096400e-64        NaN            NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge datasets on instrument and year\n",
    "merge_keys = ['instrument', 'year']\n",
    "\n",
    "# Add prefixes to distinguish variables (except merge keys and final DD/PD)\n",
    "accounting_cols_to_prefix = [c for c in df_accounting.columns \n",
    "                             if c not in merge_keys + ['DD_a', 'PD_a']]\n",
    "market_cols_to_prefix = [c for c in df_market.columns \n",
    "                         if c not in merge_keys + ['DD_m', 'PD_m']]\n",
    "\n",
    "df_accounting_prefixed = df_accounting.rename(\n",
    "    columns={c: f'a_{c}' for c in accounting_cols_to_prefix}\n",
    ")\n",
    "df_market_prefixed = df_market.rename(\n",
    "    columns={c: f'm_{c}' for c in market_cols_to_prefix}\n",
    ")\n",
    "\n",
    "# Perform outer merge to keep all observations\n",
    "df_merged = pd.merge(\n",
    "    df_accounting_prefixed,\n",
    "    df_market_prefixed,\n",
    "    on=merge_keys,\n",
    "    how='outer',\n",
    "    suffixes=('_a', '_m')\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset: {len(df_merged)} rows\")\n",
    "print(f\"\\nColumn count:\")\n",
    "print(f\"  Accounting: {len(df_accounting.columns)}\")\n",
    "print(f\"  Market: {len(df_market.columns)}\")\n",
    "print(f\"  Merged: {len(df_merged.columns)}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample merged data:\")\n",
    "display(df_merged[['instrument', 'year', 'DD_a', 'PD_a', 'DD_m', 'PD_m']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ARCHIVE] Moved to archive: merged_20251004_050658.csv\n",
      "[INFO] Merged dataset saved to: /Users/guillaumebld/Documents/Graduate_Research/Professor Abol Jalilvand/fall2025/risk_bank/risk_bank/data/outputs/datasheet/merged_20251004_051328.csv\n",
      "[INFO] Total rows: 1425\n",
      "[INFO] Total columns: 73\n"
     ]
    }
   ],
   "source": [
    "# Archive old merged files and save new one with timestamp\n",
    "archive_old_files(output_dir, archive_dir, 'merged', max_keep=5)\n",
    "\n",
    "timestamp = get_timestamp_cdt()\n",
    "merged_output = output_dir / f'merged_{timestamp}.csv'\n",
    "df_merged.to_csv(merged_output, index=False)\n",
    "\n",
    "print(f\"[INFO] Merged dataset saved to: {merged_output}\")\n",
    "print(f\"[INFO] Total rows: {len(df_merged)}\")\n",
    "print(f\"[INFO] Total columns: {len(df_merged.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating ESG dataset with DD/PD columns...\n",
      "  Loaded ESG data: 1427 rows, 49 columns\n",
      "  Merged ESG+DD/PD: 1431 rows, 53 columns\n",
      "  New columns: DD_a, PD_a, DD_m, PD_m\n",
      "\n",
      "[INFO] ESG+DD/PD dataset saved to: /Users/guillaumebld/Documents/Graduate_Research/Professor Abol Jalilvand/fall2025/risk_bank/risk_bank/data/outputs/datasheet/esg_dd_pd_20251004_051328.csv\n",
      "[INFO] Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>year</th>\n",
       "      <th>lnta</th>\n",
       "      <th>esg_score</th>\n",
       "      <th>DD_a</th>\n",
       "      <th>PD_a</th>\n",
       "      <th>DD_m</th>\n",
       "      <th>PD_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.728184</td>\n",
       "      <td>81.521252</td>\n",
       "      <td>8.636867</td>\n",
       "      <td>2.888782e-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2017</td>\n",
       "      <td>14.745152</td>\n",
       "      <td>82.353064</td>\n",
       "      <td>9.478464</td>\n",
       "      <td>1.290267e-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2018</td>\n",
       "      <td>14.779651</td>\n",
       "      <td>80.046519</td>\n",
       "      <td>55.513711</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.124911e-268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2019</td>\n",
       "      <td>14.804077</td>\n",
       "      <td>83.907682</td>\n",
       "      <td>7.926925</td>\n",
       "      <td>1.123191e-15</td>\n",
       "      <td>4.995781</td>\n",
       "      <td>2.929913e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2020</td>\n",
       "      <td>15.034793</td>\n",
       "      <td>85.545384</td>\n",
       "      <td>10.417968</td>\n",
       "      <td>1.026457e-25</td>\n",
       "      <td>5.212109</td>\n",
       "      <td>9.335310e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2021</td>\n",
       "      <td>15.135549</td>\n",
       "      <td>82.867509</td>\n",
       "      <td>11.619534</td>\n",
       "      <td>1.639605e-31</td>\n",
       "      <td>6.430166</td>\n",
       "      <td>6.373234e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2022</td>\n",
       "      <td>15.114542</td>\n",
       "      <td>78.672800</td>\n",
       "      <td>11.847620</td>\n",
       "      <td>1.106948e-32</td>\n",
       "      <td>5.648837</td>\n",
       "      <td>8.076836e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2023</td>\n",
       "      <td>15.170158</td>\n",
       "      <td>79.512383</td>\n",
       "      <td>10.047577</td>\n",
       "      <td>4.707697e-24</td>\n",
       "      <td>5.674581</td>\n",
       "      <td>6.951444e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BAC</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.598529</td>\n",
       "      <td>69.918468</td>\n",
       "      <td>7.767357</td>\n",
       "      <td>4.007030e-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BAC</td>\n",
       "      <td>2017</td>\n",
       "      <td>14.640227</td>\n",
       "      <td>75.384317</td>\n",
       "      <td>9.018904</td>\n",
       "      <td>9.499007e-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instrument  year       lnta  esg_score       DD_a          PD_a       DD_m  \\\n",
       "0        JPM  2016  14.728184  81.521252   8.636867  2.888782e-18        NaN   \n",
       "1        JPM  2017  14.745152  82.353064   9.478464  1.290267e-21        NaN   \n",
       "2        JPM  2018  14.779651  80.046519  55.513711  0.000000e+00  35.000000   \n",
       "3        JPM  2019  14.804077  83.907682   7.926925  1.123191e-15   4.995781   \n",
       "4        JPM  2020  15.034793  85.545384  10.417968  1.026457e-25   5.212109   \n",
       "5        JPM  2021  15.135549  82.867509  11.619534  1.639605e-31   6.430166   \n",
       "6        JPM  2022  15.114542  78.672800  11.847620  1.106948e-32   5.648837   \n",
       "7        JPM  2023  15.170158  79.512383  10.047577  4.707697e-24   5.674581   \n",
       "8        BAC  2016  14.598529  69.918468   7.767357  4.007030e-15        NaN   \n",
       "9        BAC  2017  14.640227  75.384317   9.018904  9.499007e-20        NaN   \n",
       "\n",
       "            PD_m  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2  1.124911e-268  \n",
       "3   2.929913e-07  \n",
       "4   9.335310e-08  \n",
       "5   6.373234e-11  \n",
       "6   8.076836e-09  \n",
       "7   6.951444e-09  \n",
       "8            NaN  \n",
       "9            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create ESG dataset with DD/PD columns appended\n",
    "print('[INFO] Creating ESG dataset with DD/PD columns...')\n",
    "\n",
    "# Load ESG data\n",
    "esg_file = base_dir / 'data' / 'esg_0718.csv'\n",
    "if not esg_file.exists():\n",
    "    print(f'[ERROR] ESG file not found: {esg_file}')\n",
    "else:\n",
    "    df_esg = pd.read_csv(esg_file)\n",
    "    print(f'  Loaded ESG data: {len(df_esg)} rows, {len(df_esg.columns)} columns')\n",
    "    \n",
    "    # Extract DD/PD columns from accounting and market datasets\n",
    "    dd_pd_data = df_merged[['instrument', 'year', 'DD_a', 'PD_a', 'DD_m', 'PD_m']].copy()\n",
    "    \n",
    "    # Merge ESG data with DD/PD\n",
    "    df_esg_dd = pd.merge(\n",
    "        df_esg,\n",
    "        dd_pd_data,\n",
    "        on=['instrument', 'year'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f'  Merged ESG+DD/PD: {len(df_esg_dd)} rows, {len(df_esg_dd.columns)} columns')\n",
    "    print(f'  New columns: DD_a, PD_a, DD_m, PD_m')\n",
    "    \n",
    "    # Archive old ESG+DD files\n",
    "    archive_old_files(output_dir, archive_dir, 'esg_dd_pd', max_keep=5)\n",
    "    \n",
    "    # Save with timestamp\n",
    "    esg_output = output_dir / f'esg_dd_pd_{timestamp}.csv'\n",
    "    df_esg_dd.to_csv(esg_output, index=False)\n",
    "    \n",
    "    print(f'\\n[INFO] ESG+DD/PD dataset saved to: {esg_output}')\n",
    "    print(f'[INFO] Sample data:')\n",
    "    display(df_esg_dd[['instrument', 'year', 'lnta', 'esg_score', 'DD_a', 'PD_a', 'DD_m', 'PD_m']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESG+DD/PD DATASET SUMMARY ===\n",
      "\n",
      "Total observations: 1431\n",
      "Observations with DD_a: 1415\n",
      "Observations with DD_m: 936\n",
      "Observations with both DD_a and DD_m: 936\n",
      "\n",
      "Unique instruments: 244\n",
      "Year range: 2016 - 2023\n"
     ]
    }
   ],
   "source": [
    "# Summary of ESG+DD/PD dataset\n",
    "if 'df_esg_dd' in locals():\n",
    "    print('=== ESG+DD/PD DATASET SUMMARY ===')\n",
    "    print(f'\\nTotal observations: {len(df_esg_dd)}')\n",
    "    print(f'Observations with DD_a: {df_esg_dd[\"DD_a\"].notna().sum()}')\n",
    "    print(f'Observations with DD_m: {df_esg_dd[\"DD_m\"].notna().sum()}')\n",
    "    print(f'Observations with both DD_a and DD_m: {df_esg_dd[[\"DD_a\", \"DD_m\"]].dropna().shape[0]}')\n",
    "    print(f'\\nUnique instruments: {df_esg_dd[\"instrument\"].nunique()}')\n",
    "    print(f'Year range: {df_esg_dd[\"year\"].min()} - {df_esg_dd[\"year\"].max()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MERGED DATASET SUMMARY ===\n",
      "\n",
      "Observations with both DD_a and DD_m: 930\n",
      "Observations with only DD_a: 479\n",
      "Observations with only DD_m: 0\n",
      "\n",
      "DD_a statistics:\n",
      "count    1409.000000\n",
      "mean       20.334403\n",
      "std        14.666043\n",
      "min        -3.665984\n",
      "25%        12.242458\n",
      "50%        16.616343\n",
      "75%        22.917770\n",
      "max       155.472624\n",
      "Name: DD_a, dtype: float64\n",
      "\n",
      "DD_m statistics:\n",
      "count    930.000000\n",
      "mean      12.198401\n",
      "std        8.032074\n",
      "min        1.946932\n",
      "25%        6.439077\n",
      "50%        9.538566\n",
      "75%       15.106819\n",
      "max       35.000000\n",
      "Name: DD_m, dtype: float64\n",
      "\n",
      "PD_a statistics:\n",
      "count     1.409000e+03\n",
      "mean      7.469649e-04\n",
      "std       2.667248e-02\n",
      "min       0.000000e+00\n",
      "25%      1.545023e-116\n",
      "50%       2.653631e-62\n",
      "75%       9.218141e-35\n",
      "max       9.998768e-01\n",
      "Name: PD_a, dtype: float64\n",
      "\n",
      "PD_m statistics:\n",
      "count     9.300000e+02\n",
      "mean      8.217333e-05\n",
      "std       1.093972e-03\n",
      "min      1.124911e-268\n",
      "25%       7.685700e-52\n",
      "50%       7.245797e-22\n",
      "75%       6.013341e-11\n",
      "max       2.577147e-02\n",
      "Name: PD_m, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"=== MERGED DATASET SUMMARY ===\")\n",
    "print(f\"\\nObservations with both DD_a and DD_m: {df_merged[['DD_a', 'DD_m']].dropna().shape[0]}\")\n",
    "print(f\"Observations with only DD_a: {df_merged['DD_a'].notna().sum() - df_merged[['DD_a', 'DD_m']].dropna().shape[0]}\")\n",
    "print(f\"Observations with only DD_m: {df_merged['DD_m'].notna().sum() - df_merged[['DD_a', 'DD_m']].dropna().shape[0]}\")\n",
    "\n",
    "print(f\"\\nDD_a statistics:\")\n",
    "print(df_merged['DD_a'].describe())\n",
    "\n",
    "print(f\"\\nDD_m statistics:\")\n",
    "print(df_merged['DD_m'].describe())\n",
    "\n",
    "print(f\"\\nPD_a statistics:\")\n",
    "print(df_merged['PD_a'].describe())\n",
    "\n",
    "print(f\"\\nPD_m statistics:\")\n",
    "print(df_merged['PD_m'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
