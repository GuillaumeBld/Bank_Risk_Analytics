{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c99aa5",
   "metadata": {},
   "source": [
    "# Accounting approach, Naive DD per Bharath and Shumway (2008). No solver.\n",
    "\n",
    "This notebook mirrors `dd_pd_accounting.py` and documents the naive accounting pipeline described in `docs/reference/Bharath_and_Shumway_naive_DD`.\n",
    "Instead of solving the Merton system, we follow Bharath and Shumway's proxy approach to obtain distance to default (DD) and probability of default (PD).\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Prepare the accounting panel inputs.\n",
    "2. Derive book equity and scale values to USD.\n",
    "3. Assemble proxy measures for equity, debt, volatility, and drift.\n",
    "4. Compute naive DD and PD.\n",
    "5. Persist the naive outputs for downstream analysis.\n",
    "6. Review diagnostics tied to the naive pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a5f5d",
   "metadata": {},
   "source": [
    "## 1. Environment setup\n",
    "\n",
    "Install the minimal dependencies required to reproduce the accounting workflow locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51155d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:00.079978Z",
     "iopub.status.busy": "2025-10-02T09:28:00.079755Z",
     "iopub.status.idle": "2025-10-02T09:28:01.082281Z",
     "shell.execute_reply": "2025-10-02T09:28:01.080166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /root/.pyenv/versions/3.12.10/lib/python3.12/site-packages (2.3.3)\r\n",
      "Requirement already satisfied: numpy in /root/.pyenv/versions/3.12.10/lib/python3.12/site-packages (2.3.3)\r\n",
      "Requirement already satisfied: scipy in /root/.pyenv/versions/3.12.10/lib/python3.12/site-packages (1.16.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /root/.pyenv/versions/3.12.10/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install needed packages (run once per environment)\n",
    "%pip install pandas numpy scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23e4966",
   "metadata": {},
   "source": [
    "## 2. Imports and file paths\n",
    "\n",
    "Load the libraries used throughout the naive pipeline and point to the accounting inputs/outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265bd56d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:01.087259Z",
     "iopub.status.busy": "2025-10-02T09:28:01.086680Z",
     "iopub.status.idle": "2025-10-02T09:28:02.198136Z",
     "shell.execute_reply": "2025-10-02T09:28:02.197304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository root: /workspace/risk_bank\n",
      "Accounting input     -> FOUND\n",
      "Market cap input     -> FOUND\n",
      "Equity vol input     -> FOUND\n",
      "Risk-free input      -> FOUND\n",
      "Account log file     -> FOUND\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import root\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Helper function for standardizing tickers\n",
    "def standardize_ticker(t):\n",
    "    return str(t).split('.', 1)[0] if pd.notnull(t) else t\n",
    "\n",
    "def find_repo_root(start: Path, marker: str = '.git') -> Path:\n",
    "    \"\"\"Walk up from *start* until a directory containing *marker* is found.\"\"\"\n",
    "    current = start.resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        if (candidate / marker).exists():\n",
    "            return candidate\n",
    "    return current\n",
    "\n",
    "# 1. Locate the repository root and define core paths\n",
    "base_dir = find_repo_root(Path.cwd())\n",
    "print(f'Repository root: {base_dir}')\n",
    "\n",
    "# 2. Time horizon for the Merton model (1 year)\n",
    "T = 1.0\n",
    "\n",
    "# 3. Define all file paths relative to base_dir\n",
    "model_fp      = base_dir / 'data' / 'clean' / 'Book2_clean.csv'\n",
    "marketcap_fp  = base_dir / 'data' / 'clean' / 'all_banks_marketcap_annual_2016_2023.csv'\n",
    "vol_fp        = base_dir / 'data' / 'clean' / 'equity_volatility_by_year.csv'\n",
    "rf_fp         = base_dir / 'data' / 'clean' / 'fama_french_factors_annual_clean.csv'\n",
    "log_fp        = base_dir / 'data' / 'logs' / 'dd_pd_accounting_log.txt'\n",
    "output_fp     = base_dir / 'data' / 'merged_inputs' / 'dd_pd_accounting.csv'\n",
    "\n",
    "# 4. Ensure directories exist\n",
    "for directory in (model_fp.parent, marketcap_fp.parent, vol_fp.parent, rf_fp.parent, log_fp.parent, output_fp.parent):\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 5. Quick existence check for inputs and outputs\n",
    "for name, fp in [\n",
    "    ('Accounting input',    model_fp),\n",
    "    ('Market cap input',    marketcap_fp),\n",
    "    ('Equity vol input',    vol_fp),\n",
    "    ('Risk-free input',     rf_fp),\n",
    "    ('Account log file',    log_fp)\n",
    "]:\n",
    "    status = 'FOUND' if fp.exists() else f'MISSING ({fp.name})'\n",
    "    print(f'{name:20s} -> {status}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f843706",
   "metadata": {},
   "source": [
    "## 3. Data preparation\n",
    "\n",
    "- Read `Book2_clean.csv` and inspect firm-year coverage.\n",
    "- Rename `nstrument` to `instrument`, enforce integer years, and normalize column names.\n",
    "- Convert totals expressed in millions to absolute USD amounts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1062fa9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:02.200788Z",
     "iopub.status.busy": "2025-10-02T09:28:02.200427Z",
     "iopub.status.idle": "2025-10-02T09:28:02.230778Z",
     "shell.execute_reply": "2025-10-02T09:28:02.230107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading accounting data...\n",
      "\u2192 1425 rows, 1424 unique (instrument, year)\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Loading accounting data...')\n",
    "df = pd.read_csv(model_fp)\n",
    "print(f\"\u2192 {df.shape[0]} rows, {df[['instrument','year']].drop_duplicates().shape[0]} unique (instrument, year)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849640b7",
   "metadata": {},
   "source": [
    "## 4. Book equity and capital structure inputs\n",
    "\n",
    "- Compute book equity `(total_assets - debt_total) * 1e6` with guards against negatives.\n",
    "- Form debt face value `F = debt_total * 1e6`.\n",
    "- Track the status flags that identify unusable or missing inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdcc2287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:02.233146Z",
     "iopub.status.busy": "2025-10-02T09:28:02.232897Z",
     "iopub.status.idle": "2025-10-02T09:28:02.262855Z",
     "shell.execute_reply": "2025-10-02T09:28:02.262145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>year</th>\n",
       "      <th>rit_rf</th>\n",
       "      <th>rit</th>\n",
       "      <th>new_wacc</th>\n",
       "      <th>unnamed:_5</th>\n",
       "      <th>weighted_average_cost_of_capital,_(%)</th>\n",
       "      <th>beta_levered</th>\n",
       "      <th>beta_unlevered</th>\n",
       "      <th>environmental_pillar_score</th>\n",
       "      <th>...</th>\n",
       "      <th>wacc_tax_rate,_(%)</th>\n",
       "      <th>wacc_cost_of_debt,_(%)</th>\n",
       "      <th>wacc_debt_weight,_(%)</th>\n",
       "      <th>wacc_equity_weight,_(%)</th>\n",
       "      <th>total_assets</th>\n",
       "      <th>debt_total</th>\n",
       "      <th>d/e</th>\n",
       "      <th>dummylarge</th>\n",
       "      <th>dummymid</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.245917</td>\n",
       "      <td>0.247917</td>\n",
       "      <td>1.584416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.864093</td>\n",
       "      <td>1.536081</td>\n",
       "      <td>0.606612</td>\n",
       "      <td>81.766775</td>\n",
       "      <td>...</td>\n",
       "      <td>29.05903</td>\n",
       "      <td>2.126534</td>\n",
       "      <td>66.065751</td>\n",
       "      <td>30.587868</td>\n",
       "      <td>2490972.0</td>\n",
       "      <td>495354.0</td>\n",
       "      <td>2.159868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.223383</td>\n",
       "      <td>0.231383</td>\n",
       "      <td>1.657157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.749802</td>\n",
       "      <td>1.210898</td>\n",
       "      <td>0.579144</td>\n",
       "      <td>83.079770</td>\n",
       "      <td>...</td>\n",
       "      <td>28.38487</td>\n",
       "      <td>2.189746</td>\n",
       "      <td>58.567477</td>\n",
       "      <td>38.450277</td>\n",
       "      <td>2533600.0</td>\n",
       "      <td>494798.0</td>\n",
       "      <td>1.523200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.227840</td>\n",
       "      <td>-0.209740</td>\n",
       "      <td>1.869560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.749097</td>\n",
       "      <td>1.141127</td>\n",
       "      <td>0.577758</td>\n",
       "      <td>79.426260</td>\n",
       "      <td>...</td>\n",
       "      <td>28.38487</td>\n",
       "      <td>2.730852</td>\n",
       "      <td>55.921812</td>\n",
       "      <td>41.071387</td>\n",
       "      <td>2622532.0</td>\n",
       "      <td>533627.0</td>\n",
       "      <td>1.361576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.161746</td>\n",
       "      <td>0.183146</td>\n",
       "      <td>1.548871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.696227</td>\n",
       "      <td>1.223974</td>\n",
       "      <td>0.561719</td>\n",
       "      <td>89.750677</td>\n",
       "      <td>...</td>\n",
       "      <td>26.62674</td>\n",
       "      <td>2.017936</td>\n",
       "      <td>59.874307</td>\n",
       "      <td>37.262556</td>\n",
       "      <td>2687379.0</td>\n",
       "      <td>516093.0</td>\n",
       "      <td>1.606822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2020</td>\n",
       "      <td>-0.128976</td>\n",
       "      <td>-0.124576</td>\n",
       "      <td>0.989988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.732273</td>\n",
       "      <td>1.217916</td>\n",
       "      <td>0.487232</td>\n",
       "      <td>90.723262</td>\n",
       "      <td>...</td>\n",
       "      <td>21.07742</td>\n",
       "      <td>1.306948</td>\n",
       "      <td>63.283852</td>\n",
       "      <td>33.304242</td>\n",
       "      <td>3384757.0</td>\n",
       "      <td>542102.0</td>\n",
       "      <td>1.900174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  instrument  year    rit_rf       rit  new_wacc  unnamed:_5  \\\n",
       "0        JPM  2016  0.245917  0.247917  1.584416         NaN   \n",
       "1        JPM  2017  0.223383  0.231383  1.657157         NaN   \n",
       "2        JPM  2018 -0.227840 -0.209740  1.869560         NaN   \n",
       "3        JPM  2019  0.161746  0.183146  1.548871         NaN   \n",
       "4        JPM  2020 -0.128976 -0.124576  0.989988         NaN   \n",
       "\n",
       "   weighted_average_cost_of_capital,_(%)  beta_levered  beta_unlevered  \\\n",
       "0                               4.864093      1.536081        0.606612   \n",
       "1                               4.749802      1.210898        0.579144   \n",
       "2                               5.749097      1.141127        0.577758   \n",
       "3                               4.696227      1.223974        0.561719   \n",
       "4                               3.732273      1.217916        0.487232   \n",
       "\n",
       "   environmental_pillar_score  ...  wacc_tax_rate,_(%)  \\\n",
       "0                   81.766775  ...            29.05903   \n",
       "1                   83.079770  ...            28.38487   \n",
       "2                   79.426260  ...            28.38487   \n",
       "3                   89.750677  ...            26.62674   \n",
       "4                   90.723262  ...            21.07742   \n",
       "\n",
       "   wacc_cost_of_debt,_(%)  wacc_debt_weight,_(%)  wacc_equity_weight,_(%)  \\\n",
       "0                2.126534              66.065751                30.587868   \n",
       "1                2.189746              58.567477                38.450277   \n",
       "2                2.730852              55.921812                41.071387   \n",
       "3                2.017936              59.874307                37.262556   \n",
       "4                1.306948              63.283852                33.304242   \n",
       "\n",
       "   total_assets  debt_total       d/e  dummylarge  dummymid  Year  \n",
       "0     2490972.0    495354.0  2.159868         1.0       0.0  2016  \n",
       "1     2533600.0    494798.0  1.523200         1.0       0.0  2017  \n",
       "2     2622532.0    533627.0  1.361576         1.0       0.0  2018  \n",
       "3     2687379.0    516093.0  1.606822         1.0       0.0  2019  \n",
       "4     3384757.0    542102.0  1.900174         1.0       0.0  2020  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize column names\n",
    "col_map = {c: re.sub(r'_+', '_', c.strip().lower()\n",
    "                        .replace(' ', '_')\n",
    "                        .replace('-', '_'))\n",
    "           for c in df.columns}\n",
    "df = df.rename(columns=col_map)\n",
    "\n",
    "# Extract or clean 'year'\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df['year'] = df['date'].dt.year\n",
    "else:\n",
    "    df = df[df['year'].notnull()].copy()\n",
    "    df['year'] = df['year'].astype(float).astype(int)\n",
    "\n",
    "df['Year'] = df['year']  # for merges down the line\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0bfcb5",
   "metadata": {},
   "source": [
    "## 5. Proxy calculations\n",
    "\n",
    "- Construct market equity proxies (price-to-book, D/E, WACC weights) and record the chosen source.\n",
    "- Estimate equity volatility from trailing returns and apply the debt volatility proxy `0.05 + 0.25 * sigma_E`.\n",
    "- Combine proxies to obtain `V_hat`, `sigma_V_hat`, and the drift proxy `mu_hat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d6025f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:02.265386Z",
     "iopub.status.busy": "2025-10-02T09:28:02.265141Z",
     "iopub.status.idle": "2025-10-02T09:28:02.318961Z",
     "shell.execute_reply": "2025-10-02T09:28:02.318186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After prep, df columns: ['instrument', 'year', 'rit_rf', 'rit', 'new_wacc', 'unnamed:_5', 'weighted_average_cost_of_capital,_(%)', 'beta_levered', 'beta_unlevered', 'environmental_pillar_score', 'social_pillar_score', 'governance_pillar_score', 'esg_score', 'esg_combined_score', 'environmental_pillar_score_1', 'social_pillar_score_1', 'governance_pillar_score_1', 'esg_score_1', 'esg_combined_score_1', 'lnta', 'td/ta', 'price_to_book_value_per_share', 'capital_adequacy_total_(%)', 'wacc_tax_rate,_(%)', 'wacc_cost_of_debt,_(%)', 'wacc_debt_weight,_(%)', 'wacc_equity_weight,_(%)', 'total_assets', 'debt_total', 'd/e', 'dummylarge', 'dummymid', 'Year', 'ticker_prefix']\n",
      "Unique df keys:   ticker_prefix  Year\n",
      "0           JPM  2016\n",
      "1           JPM  2017\n",
      "2           JPM  2018\n",
      "3           JPM  2019\n",
      "4           JPM  2020\n",
      "mc columns: ['symbol', 'year', 'market_cap', 'ticker_prefix', 'Year']\n",
      "Sample mc keys:   ticker_prefix  Year    market_cap\n",
      "0          ABCB  2016  3.004515e+09\n",
      "1          ABCB  2017  3.321505e+09\n",
      "2          ABCB  2018  2.182408e+09\n",
      "3          ABCB  2019  2.931470e+09\n",
      "4          ABCB  2020  2.623438e+09\n",
      "ev columns: ['symbol', 'year', 'equity_volatility', 'equity_volatility_note', 'ticker_prefix', 'Year']\n",
      "Sample ev keys:   ticker_prefix  Year  equity_volatility\n",
      "0           SSB  2015                NaN\n",
      "1           SSB  2016           0.229291\n",
      "2           SSB  2017           0.145237\n",
      "3           SSB  2018           0.266805\n",
      "4           SSB  2019           0.272685\n",
      "[WARN] equity_volatility missing; defaulted to 0.25 for:\n",
      "instrument  year\n",
      "      COFS  2019\n",
      "After merges, sample df:\n",
      "  ticker_prefix  Year    market_cap  equity_vol      rf\n",
      "0           JPM  2016  2.398077e+11    0.206735  0.0020\n",
      "1           JPM  2017  2.971959e+11    0.169109  0.0080\n",
      "2           JPM  2018  2.712948e+11    0.185040  0.0181\n",
      "3           JPM  2019  3.874051e+11    0.227006  0.0214\n",
      "4           JPM  2020  3.531390e+11    0.382475  0.0044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 5: Prepare merge keys in df ---\n",
    "# 5.0 Ensure df has ticker_prefix & Year\n",
    "if 'ticker_prefix' not in df.columns:\n",
    "    df['ticker_prefix'] = df['instrument'].apply(standardize_ticker)\n",
    "if 'Year' not in df.columns:\n",
    "    # prefer existing year column\n",
    "    if 'year' in df.columns:\n",
    "        df['Year'] = df['year']\n",
    "    else:\n",
    "        df['Year'] = pd.to_datetime(df['date'], errors='coerce').dt.year\n",
    "\n",
    "# Quick debug\n",
    "print('After prep, df columns:', df.columns.tolist())\n",
    "print('Unique df keys:', df[['ticker_prefix','Year']].drop_duplicates().head())\n",
    "\n",
    "# --- 5.1 Load and merge market capitalization ---\n",
    "mc = pd.read_csv(marketcap_fp)\n",
    "\n",
    "# Compute market_cap if needed\n",
    "if 'market_cap' not in mc.columns:\n",
    "    mc['market_cap'] = mc['dec_price'] * mc['shares_outstanding']\n",
    "\n",
    "# Ensure mc has the merge keys\n",
    "if 'ticker_prefix' not in mc.columns:\n",
    "    mc['ticker_prefix'] = mc['symbol'].apply(standardize_ticker)\n",
    "if 'Year' not in mc.columns:\n",
    "    mc['Year'] = mc['year']\n",
    "\n",
    "# Debug\n",
    "print('mc columns:', mc.columns.tolist())\n",
    "print('Sample mc keys:', mc[['ticker_prefix','Year','market_cap']].head())\n",
    "\n",
    "# Merge\n",
    "df = df.merge(\n",
    "    mc[['ticker_prefix','Year','market_cap']],\n",
    "    on=['ticker_prefix','Year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- 5.2 Load and merge equity volatility ---\n",
    "ev = pd.read_csv(vol_fp)\n",
    "\n",
    "# Determine ticker column in ev\n",
    "ticker_col = 'symbol' if 'symbol' in ev.columns else 'Bank'\n",
    "if 'ticker_prefix' not in ev.columns:\n",
    "    ev['ticker_prefix'] = ev[ticker_col].apply(standardize_ticker)\n",
    "if 'Year' not in ev.columns:\n",
    "    ev['Year'] = ev['year'] if 'year' in ev.columns else ev['Year']\n",
    "\n",
    "# Debug\n",
    "print('ev columns:', ev.columns.tolist())\n",
    "print('Sample ev keys:', ev[['ticker_prefix','Year','equity_volatility']].head())\n",
    "\n",
    "# Merge and create audit trail for fallbacks\n",
    "if 'equity_vol_default_entries' not in globals():\n",
    "    equity_vol_default_entries = []\n",
    "\n",
    "df = df.merge(\n",
    "    ev[['ticker_prefix','Year','equity_volatility']],\n",
    "    on=['ticker_prefix','Year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "missing_equity_vol = df['equity_volatility'].isna()\n",
    "df['equity_vol_is_default'] = missing_equity_vol\n",
    "df['equity_vol'] = df['equity_volatility'].fillna(0.25)\n",
    "\n",
    "if missing_equity_vol.any():\n",
    "    fallback_pairs = (\n",
    "        df.loc[missing_equity_vol, ['instrument', 'year']]\n",
    "          .drop_duplicates()\n",
    "          .sort_values(['instrument', 'year'])\n",
    "    )\n",
    "    print('[WARN] equity_volatility missing; defaulted to 0.25 for:')\n",
    "    print(fallback_pairs.to_string(index=False))\n",
    "    for _, row in fallback_pairs.iterrows():\n",
    "        equity_vol_default_entries.append(\n",
    "            f\"Equity vol fallback -> instrument={row['instrument']}, year={int(row['year'])}, default_sigma_E=0.25\"\n",
    "        )\n",
    "else:\n",
    "    print('[INFO] No equity volatility fallbacks applied.')\n",
    "\n",
    "# --- 5.3 Load and merge risk-free rate ---\n",
    "rf = pd.read_csv(rf_fp)\n",
    "if 'Year' not in rf.columns:\n",
    "    rf['Year'] = rf['year']\n",
    "rf = rf[['Year','rf']].copy()\n",
    "rf['rf'] = rf['rf'] / 100  # convert percent to decimal\n",
    "\n",
    "df = df.merge(rf, on='Year', how='left')\n",
    "\n",
    "print('After merges, sample df:')\n",
    "print(df[['ticker_prefix','Year','market_cap','equity_vol','rf']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef256acd",
   "metadata": {},
   "source": [
    "## 6. Naive DD and PD\n",
    "\n",
    "With proxy inputs in place, compute the Bharath and Shumway metrics:\n",
    "\n",
    "- Distance to default\n",
    "  $$\\mathrm{DD}_{\text{naive}} = \frac{\\ln(\\hat V / F) + (\\hat\\mu - \tfrac{1}{2}\\hat\\sigma_V^2)T}{\\hat\\sigma_V\\sqrt{T}},\\quad T=1$$\n",
    "- Probability of default\n",
    "  $$\\mathrm{PD}_{\text{naive}} = \\Phi\bigl(-\\mathrm{DD}_{\text{naive}}\bigr)$$\n",
    "\n",
    "Ensure invalid inputs propagate `NaN` outputs and retain narrative flags (e.g., `naive_status`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23556a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:02.321125Z",
     "iopub.status.busy": "2025-10-02T09:28:02.320933Z",
     "iopub.status.idle": "2025-10-02T09:28:02.331721Z",
     "shell.execute_reply": "2025-10-02T09:28:02.331082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPM 2016: V = 2489982282047.86, sigma_V = 0.1657, status = converged\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import root\n",
    "\n",
    "\n",
    "def merton_solver_accounting(row, T=T):\n",
    "    \"\"\"Solve for asset value and volatility using accounting inputs.\"\"\"\n",
    "    # 1. Extract inputs (convert millions to actual USD)\n",
    "    rf = row['rf']\n",
    "    A = row['total_assets'] * 1_000_000  # book assets in USD\n",
    "    F = row['debt_total'] * 1_000_000    # book debt in USD\n",
    "    sigma_E = row['equity_vol']          # equity volatility (decimal)\n",
    "    E = A - F                            # net equity in USD\n",
    "\n",
    "    # 2. Validate inputs\n",
    "    if pd.isna(A) or pd.isna(F) or pd.isna(sigma_E) or pd.isna(rf) or A <= 0 or sigma_E <= 0 or F < 0:\n",
    "        return np.nan, np.nan, 'invalid', 'missing_or_invalid'\n",
    "    if F == 0:\n",
    "        return np.nan, np.nan, 'no_debt', 'no_debt'\n",
    "    if E <= 0:\n",
    "        return np.nan, np.nan, 'negative_equity', 'negative_equity'\n",
    "\n",
    "    # 3. Define the Merton equations\n",
    "    def equations(x):\n",
    "        V, sigma_V = x\n",
    "        if V <= 0 or sigma_V <= 0:\n",
    "            return [1e6, 1e6]\n",
    "        d1 = (np.log(V / F) + (rf + 0.5 * sigma_V**2) * T) / (sigma_V * np.sqrt(T))\n",
    "        d2 = d1 - sigma_V * np.sqrt(T)\n",
    "        eq1 = V * norm.cdf(d1) - F * np.exp(-rf * T) * norm.cdf(d2) - E\n",
    "        eq2 = sigma_E - (V / E) * norm.cdf(d1) * sigma_V\n",
    "        return [eq1, eq2]\n",
    "\n",
    "    # 4. Initial guess and solve\n",
    "    try:\n",
    "        sol = root(equations, [A, sigma_E], method='hybr')\n",
    "        if sol.success and sol.x[0] > 0 and sol.x[1] > 0:\n",
    "            V_opt, sigma_V_opt = sol.x\n",
    "            return V_opt, sigma_V_opt, 'converged', ''\n",
    "        return np.nan, np.nan, 'no_converge', ''\n",
    "    except Exception as err:\n",
    "        return np.nan, np.nan, 'error', f'solver_error:{err.__class__.__name__}'\n",
    "\n",
    "\n",
    "# Quick smoke test on the first row\n",
    "if not df.empty:\n",
    "    demo = df.iloc[0]\n",
    "    V0, sigma_V0, status0, tag0 = merton_solver_accounting(demo)\n",
    "    print(f\"{demo['instrument']} {demo['year']}: V = {V0:.2f}, sigma_V = {sigma_V0:.4f}, status = {status0}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b734210",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ab29a3",
   "metadata": {},
   "source": [
    "## 7. Outputs\n",
    "\n",
    "- Persist the firm-year results (keys, proxy components, DD/PD, status fields) to `dd_pd_naive.csv`.\n",
    "- Summarize DD/PD percentiles by year and overall in `dd_pd_naive_summary.csv`.\n",
    "- Document the equity source and imputation flags alongside the metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f3989f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:02.333635Z",
     "iopub.status.busy": "2025-10-02T09:28:02.333452Z",
     "iopub.status.idle": "2025-10-02T09:28:04.298615Z",
     "shell.execute_reply": "2025-10-02T09:28:04.297872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Applying accounting-based Merton solver to each row\u2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  instrument  year   asset_value  asset_vol        DDa           PDa\n",
      "0        JPM  2016  2.489982e+12   0.165689   9.662851  2.168117e-22\n",
      "1        JPM  2017  2.529657e+12   0.136295  11.903572  5.669392e-33\n",
      "2        JPM  2018  2.612960e+12   0.147929  10.664598  7.452139e-27\n",
      "3        JPM  2019  2.676452e+12   0.184160   8.845568  4.553215e-19\n",
      "4        JPM  2020  3.382377e+12   0.321444   5.535074  1.555488e-08\n",
      "\n",
      "Solver status counts:\n",
      " merton_status\n",
      "converged      1407\n",
      "no_debt          16\n",
      "no_converge       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Apply the solver\n",
    "print(\"[INFO] Applying accounting-based Merton solver to each row\u2026\")\n",
    "results = df.apply(merton_solver_accounting, axis=1, result_type='expand')\n",
    "df[['asset_value','asset_vol','merton_status','dd_pd_tag']] = results\n",
    "\n",
    "# 7.2 Compute DDa and PDa\n",
    "V   = df['asset_value']\n",
    "F   = df['debt_total'] * 1_000_000  #  Convert debt to actual USD for consistent calculation\n",
    "sigma_V = df['asset_vol']\n",
    "\n",
    "# Numerator: log distance + drift (drift term uses r_f=0 here)\n",
    "num = np.log(V / F) + (0.0 - 0.5 * sigma_V**2) * T\n",
    "# Denominator: volatility \u00d7 sqrt(T)\n",
    "den = sigma_V * np.sqrt(T)\n",
    "\n",
    "df['DDa'] = np.where(\n",
    "    (df['dd_pd_tag']=='no_debt') | (df['dd_pd_tag']=='negative_equity'), \n",
    "    np.nan, \n",
    "    num / den\n",
    ")\n",
    "df['PDa'] = np.where(\n",
    "    (df['dd_pd_tag']=='no_debt') | (df['dd_pd_tag']=='negative_equity'), \n",
    "    np.nan, \n",
    "    norm.cdf(-df['DDa'])\n",
    ")\n",
    "\n",
    "# 7.3 Quick check of results\n",
    "print(df[['instrument','year','asset_value','asset_vol','DDa','PDa']].head())\n",
    "print(\"\\nSolver status counts:\\n\", df['merton_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62b3af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aa231fe",
   "metadata": {},
   "source": [
    "## 8. Diagnostics and logging\n",
    "\n",
    "- Append processing counts, proxy usage, and distributional stats to the accounting log.\n",
    "- Visualize naive DD/PD distributions or compare against market-based metrics when available.\n",
    "- Review any status codes indicating missing proxies or imputed volatilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4ef07",
   "metadata": {},
   "source": [
    "## 9. Summary and next steps\n",
    "\n",
    "**What we\u2019ve accomplished**\n",
    "- Executed the Bharath and Shumway naive accounting pipeline end-to-end.\n",
    "- Generated book-based DD/PD metrics without invoking the iterative solver.\n",
    "- Captured proxy provenance and quality diagnostics for downstream review.\n",
    "\n",
    "**Next steps**\n",
    "1. Audit `naive_status` and volatility imputation flags before consumption.\n",
    "2. Contrast naive metrics with market-based results for the overlapping sample.\n",
    "3. Incorporate the naive DD/PD outputs into your broader risk analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a103560f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T09:28:04.300989Z",
     "iopub.status.busy": "2025-10-02T09:28:04.300767Z",
     "iopub.status.idle": "2025-10-02T09:28:04.394063Z",
     "shell.execute_reply": "2025-10-02T09:28:04.393337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Accounting-based DD/PD results saved to: /workspace/risk_bank/data/merged_inputs/dd_pd_accounting.csv\n",
      "[INFO] Diagnostics appended to: /workspace/risk_bank/data/logs/dd_pd_accounting_log.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8.1 Export the DataFrame to CSV (accounting-based)\n",
    "output_fp = base_dir / 'data' / 'merged_inputs' / 'dd_pd_accounting.csv'\n",
    "log_fp    = base_dir / 'data' / 'logs' / 'dd_pd_accounting_log.txt'\n",
    "\n",
    "df.to_csv(output_fp, index=False)\n",
    "print('[INFO] Accounting-based DD/PD results saved to:', output_fp.resolve())\n",
    "\n",
    "# 8.2 Append diagnostics and audit trail to the log\n",
    "dd_col = 'DDa' if 'DDa' in df.columns else next((c for c in df.columns if 'distance' in c.lower()), None)\n",
    "pd_col = 'PDa' if 'PDa' in df.columns else next((c for c in df.columns if 'probability' in c.lower()), None)\n",
    "status_col = ('merton_status' if 'merton_status' in df.columns\n",
    "              else 'solver_status' if 'solver_status' in df.columns\n",
    "              else None)\n",
    "\n",
    "with open(log_fp, 'a') as log:\n",
    "    log.write('\\n=== Accounting-Based DD/PD Diagnostics ===\\n')\n",
    "    log.write(f'Total rows processed: {len(df)}\\n')\n",
    "\n",
    "    if status_col:\n",
    "        log.write(f'\\n{status_col} counts:\\n')\n",
    "        log.write(df[status_col].value_counts().to_string() + '\\n')\n",
    "    else:\n",
    "        log.write('\\nNo solver-status column found. Available columns:\\n')\n",
    "        log.write(', '.join(df.columns) + '\\n')\n",
    "\n",
    "    if dd_col:\n",
    "        log.write(f'\\nDistance to Default ({dd_col}) summary:\\n')\n",
    "        log.write(df[dd_col].describe().to_string() + '\\n')\n",
    "        log.write(f'Rows with missing {dd_col}: {df[dd_col].isna().sum()}\\n')\n",
    "    if pd_col:\n",
    "        log.write(f'\\nProbability of Default ({pd_col}) summary:\\n')\n",
    "        log.write(df[pd_col].describe().to_string() + '\\n')\n",
    "        log.write(f'Rows with missing {pd_col}: {df[pd_col].isna().sum()}\\n')\n",
    "\n",
    "    if 'equity_vol_default_entries' in globals() and equity_vol_default_entries:\n",
    "        log.write('\\nEquity volatility fallbacks applied:\\n')\n",
    "        log.write('\\n'.join(equity_vol_default_entries) + '\\n')\n",
    "    else:\n",
    "        log.write('\\nEquity volatility fallbacks applied: none\\n')\n",
    "\n",
    "print('[INFO] Diagnostics appended to:', log_fp.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}